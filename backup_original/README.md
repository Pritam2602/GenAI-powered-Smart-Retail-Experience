## GenAI-powered Smart Retail Experience

This repository contains datasets and a scraping notebook to build a smart retail experience for fashion products. It aggregates product metadata from Flipkart and Myntra and optionally downloads product images for downstream GenAI tasks (e.g., product search, captioning, recommendation).

### Repository structure

- `Data_Collection.ipynb`: Notebook that scrapes Flipkart categories, downloads images into `fashion_images/`, and writes a consolidated CSV `fashion_dataset_full.csv`.
- `flipkart_fashion_data_detailed.csv`: Curated Flipkart sample with ratings and reviews.
- `myntra202305041052.csv`: Large Myntra export (very big file).
- `fashion_images/`: Folder where the notebook saves downloaded product images.

### Environment setup

The notebook expects Python with the following packages:

```bash
pip install requests beautifulsoup4 pandas
```

Recommended: use a recent Python 3 environment (Anaconda works well).

### Notebook overview (`Data_Collection.ipynb`)

The notebook:
- Creates `fashion_images/` if it does not exist.
- Iterates categories such as men t-shirts, jeans, shoes; women dresses, tops, sarees; handbags, unisex sneakers, kids clothes.
- For each category and the first 2 result pages, collects product links, opens each product page, and extracts:
  - `product_name`, `brand` (derived from name), `price`, `rating`, `description/highlights`, `image_url`, `product_link`.
- Downloads the primary product image to `fashion_images/` using a sanitized filename.
- Saves all rows into `fashion_dataset_full.csv` in the project root.

Notes:
- The scraper depends on Flipkart HTML structure and may break if class names change.
- Network delays and rate limiting are throttled with a 1s sleep per item; adjust responsibly.

### Datasets

1) `flipkart_fashion_data_detailed.csv` (sample header):

Columns:
- `brand`: Brand name (e.g., ADIDAS, Roadster)
- `name`: Product title shown on the site
- `product_url`: Product detail page URL
- `price`: Price string including currency (e.g., `â‚¹584`)
- `image_url`: Primary image URL
- `rating`: Numeric rating if available (e.g., `4.2`)
- `rating_summary`: Aggregate text summary (e.g., `1,373 ratings and 40 reviews`)
- `review_comment`: Example review text when present

2) `myntra202305041052.csv`:

- Very large CSV export from Myntra. Load with chunking to avoid running out of memory.

Example (pandas):
```python
import pandas as pd

chunks = pd.read_csv('myntra202305041052.csv', chunksize=100000)
for i, chunk in enumerate(chunks):
    print('Chunk', i, chunk.shape)
    # process chunk
```

3) `fashion_dataset_full.csv` (generated by the notebook):

- Columns: `category`, `product_name`, `brand`, `price`, `rating`, `description`, `image_name`, `image_url`, `product_link`.
- Image files saved under `fashion_images/` with sanitized names.

### Usage

1. Open `Data_Collection.ipynb` and run all cells.
2. Adjust the `queries` list in the notebook to target categories of interest.
3. After completion, use `fashion_dataset_full.csv` and images for downstream tasks (e.g., fine-tuning, RAG, vector search).

### Handling large files

- `myntra202305041052.csv` exceeds typical memory limits. Use pandas `chunksize` or tools like DuckDB/Polars for efficient processing.
- Avoid committing derived large files unless necessary.

### Ethical and legal considerations

- Respect robots.txt, terms of service, and local regulations. This code is for educational purposes. If scraping external sites, ensure you have permission and apply courteous rate limits.

### Next steps (ideas)

- Add robust scraping with request headers, retries, and structured parsers.
- Normalize currencies and price formats; coerce ratings to numeric.
- Add image embeddings and text embeddings to enable multimodal search.
- Build a simple Streamlit/Gradio demo to browse and search products.

### License

MIT.


